2025-04-15 08:18:59.605131: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-15 08:18:59.606971: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2025-04-15 08:18:59.664588: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2025-04-15 08:18:59.665063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-15 08:19:00.315342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

 Client 1 Data Summary
  Total samples: 400
  COVID samples: 320
  Non-COVID samples: 80
  Training samples: 360
    ↳ COVID: 288, Non-COVID: 72
  Validation samples: 40
    ↳ COVID: 32, Non-COVID: 8
Client 1 connected to server.
Epoch 1/5
 1/12 [=>............................] - ETA: 17s - loss: 5.2252 - accuracy: 0.7500 2/12 [====>.........................] - ETA: 2s - loss: 4.9484 - accuracy: 0.8281  3/12 [======>.......................] - ETA: 1s - loss: 5.5544 - accuracy: 0.7812 4/12 [=========>....................] - ETA: 1s - loss: 5.6692 - accuracy: 0.7500 5/12 [===========>..................] - ETA: 1s - loss: 5.6021 - accuracy: 0.7375 6/12 [==============>...............] - ETA: 1s - loss: 5.4156 - accuracy: 0.7656 7/12 [================>.............] - ETA: 0s - loss: 5.3396 - accuracy: 0.7812 8/12 [===================>..........] - ETA: 0s - loss: 5.2831 - accuracy: 0.7891 9/12 [=====================>........] - ETA: 0s - loss: 5.2265 - accuracy: 0.784710/12 [========================>.....] - ETA: 0s - loss: 5.1582 - accuracy: 0.784411/12 [==========================>...] - ETA: 0s - loss: 5.1455 - accuracy: 0.784112/12 [==============================] - ETA: 0s - loss: 5.1371 - accuracy: 0.7833Epoch 1 took 4.04 seconds
12/12 [==============================] - 4s 222ms/step - loss: 5.1371 - accuracy: 0.7833 - val_loss: 4.3446 - val_accuracy: 0.8000
Epoch 2/5
 1/12 [=>............................] - ETA: 2s - loss: 4.2530 - accuracy: 0.9375 2/12 [====>.........................] - ETA: 1s - loss: 4.4260 - accuracy: 0.8438 3/12 [======>.......................] - ETA: 1s - loss: 4.3630 - accuracy: 0.8542 4/12 [=========>....................] - ETA: 1s - loss: 4.4823 - accuracy: 0.8203 5/12 [===========>..................] - ETA: 1s - loss: 4.4019 - accuracy: 0.8375 6/12 [==============>...............] - ETA: 1s - loss: 4.3381 - accuracy: 0.8229 7/12 [================>.............] - ETA: 0s - loss: 4.3179 - accuracy: 0.8170 8/12 [===================>..........] - ETA: 0s - loss: 4.2638 - accuracy: 0.8242 9/12 [=====================>........] - ETA: 0s - loss: 4.1916 - accuracy: 0.840310/12 [========================>.....] - ETA: 0s - loss: 4.1369 - accuracy: 0.853111/12 [==========================>...] - ETA: 0s - loss: 4.0875 - accuracy: 0.860812/12 [==============================] - ETA: 0s - loss: 4.0840 - accuracy: 0.8611Epoch 2 took 2.31 seconds
12/12 [==============================] - 2s 192ms/step - loss: 4.0840 - accuracy: 0.8611 - val_loss: 3.9442 - val_accuracy: 0.8000
Epoch 3/5
 1/12 [=>............................] - ETA: 2s - loss: 3.8643 - accuracy: 0.9062 2/12 [====>.........................] - ETA: 2s - loss: 3.7694 - accuracy: 0.9062 3/12 [======>.......................] - ETA: 2s - loss: 3.8325 - accuracy: 0.8854 4/12 [=========>....................] - ETA: 1s - loss: 3.7989 - accuracy: 0.8984 5/12 [===========>..................] - ETA: 1s - loss: 3.7296 - accuracy: 0.9000 6/12 [==============>...............] - ETA: 1s - loss: 3.6877 - accuracy: 0.9062 7/12 [================>.............] - ETA: 1s - loss: 3.6618 - accuracy: 0.9062 8/12 [===================>..........] - ETA: 0s - loss: 3.6665 - accuracy: 0.9062 9/12 [=====================>........] - ETA: 0s - loss: 3.6597 - accuracy: 0.902810/12 [========================>.....] - ETA: 0s - loss: 3.6110 - accuracy: 0.909411/12 [==========================>...] - ETA: 0s - loss: 3.5794 - accuracy: 0.9091Epoch 3 took 2.56 seconds
12/12 [==============================] - 3s 215ms/step - loss: 3.5728 - accuracy: 0.9083 - val_loss: 3.5741 - val_accuracy: 0.8000
Epoch 4/5
 1/12 [=>............................] - ETA: 2s - loss: 3.2299 - accuracy: 0.9375 2/12 [====>.........................] - ETA: 1s - loss: 3.3798 - accuracy: 0.9062 3/12 [======>.......................] - ETA: 1s - loss: 3.2822 - accuracy: 0.9271 4/12 [=========>....................] - ETA: 1s - loss: 3.2688 - accuracy: 0.9141 5/12 [===========>..................] - ETA: 1s - loss: 3.3250 - accuracy: 0.9125 6/12 [==============>...............] - ETA: 1s - loss: 3.2655 - accuracy: 0.9271 7/12 [================>.............] - ETA: 1s - loss: 3.2633 - accuracy: 0.9241 8/12 [===================>..........] - ETA: 1s - loss: 3.2247 - accuracy: 0.9336 9/12 [=====================>........] - ETA: 0s - loss: 3.2756 - accuracy: 0.909710/12 [========================>.....] - ETA: 0s - loss: 3.2412 - accuracy: 0.912511/12 [==========================>...] - ETA: 0s - loss: 3.2068 - accuracy: 0.917612/12 [==============================] - ETA: 0s - loss: 3.2168 - accuracy: 0.9167Epoch 4 took 3.18 seconds
12/12 [==============================] - 3s 272ms/step - loss: 3.2168 - accuracy: 0.9167 - val_loss: 3.3215 - val_accuracy: 0.8000
Epoch 5/5
 1/12 [=>............................] - ETA: 3s - loss: 2.7900 - accuracy: 1.0000 2/12 [====>.........................] - ETA: 3s - loss: 2.9056 - accuracy: 0.9688 3/12 [======>.......................] - ETA: 3s - loss: 2.9695 - accuracy: 0.9688 4/12 [=========>....................] - ETA: 2s - loss: 2.9905 - accuracy: 0.9531 5/12 [===========>..................] - ETA: 2s - loss: 2.9893 - accuracy: 0.9500 6/12 [==============>...............] - ETA: 2s - loss: 2.9920 - accuracy: 0.9427 7/12 [================>.............] - ETA: 1s - loss: 2.9732 - accuracy: 0.9420 8/12 [===================>..........] - ETA: 1s - loss: 2.9609 - accuracy: 0.9414 9/12 [=====================>........] - ETA: 0s - loss: 2.9624 - accuracy: 0.937510/12 [========================>.....] - ETA: 0s - loss: 2.9671 - accuracy: 0.931211/12 [==========================>...] - ETA: 0s - loss: 2.9829 - accuracy: 0.923312/12 [==============================] - ETA: 0s - loss: 2.9768 - accuracy: 0.9222Epoch 5 took 3.74 seconds
12/12 [==============================] - 4s 315ms/step - loss: 2.9768 - accuracy: 0.9222 - val_loss: 3.0855 - val_accuracy: 0.8250
Round Complete.
  CPU Usage - Avg: 31.12%, Peak: 46.95%, Min: 0.00%
  Memory Usage - Avg: 954.22 MB, Peak: 988.99 MB, Min: 658.21 MB
  Available Memory - Avg: 3111.87 MB, Peak: 3585.75 MB, Min: 2876.12 MB

=== DP Noise Injection (Round 1) ===
Epsilon: 3.0, Noise Type: gaussian
Traceback (most recent call last):
  File "/home/jmulvany/Thesis_BU/iv_VM/client_LDP.py", line 513, in <module>
    updated_weights = client.update(global_weights)
  File "/home/jmulvany/Thesis_BU/iv_VM/client_LDP.py", line 279, in update
    encrypted_weights = encrypt_weights(noisy_weights, self.tenseal_context)
  File "/home/jmulvany/Thesis_BU/iv_VM/client_LDP.py", line 82, in encrypt_weights
    enc_weight = ts.ckks_vector(ts_context, flat_weight)
  File "/home/jmulvany/Thesis_BU/venv/lib/python3.10/site-packages/tenseal/__init__.py", line 102, in ckks_vector
    return CKKSVector(*args, **kwargs)
  File "/home/jmulvany/Thesis_BU/venv/lib/python3.10/site-packages/tenseal/tensors/ckksvector.py", line 42, in __init__
    self.data = ts._ts_cpp.CKKSVector(context.data, vector)
ValueError: encoded values are too large
